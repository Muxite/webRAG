name: "euglena"
services:
  rabbitmq:
    image: rabbitmq:3-management
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    networks:
      - enet

#  inference:
#    image: ghcr.io/ggml-org/llama.cpp:server-cuda
#    volumes:
#      - ./inference/models:/models
#    environment:
#      - LLAMA_ARG_MODEL=/models/Phi-3-mini-4k-instruct-q4.gguf
#      - LLAMA_ARG_N_GPU_LAYERS=999
#      - LLAMA_ARG_PORT=8000
#      - LLAMA_ARG_HOST=0.0.0.0
#      - LLAMA_API=true
#    ports:
#      - "8000:8000"
#    entrypoint: ["/app/llama-server"]
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]
#    networks:
#      - enet

  chroma:
    image: chromadb/chroma:latest
    container_name: euglena-chroma
    ports:
      - "8001:8000"
    volumes:
      - ./chroma:/chroma-cache_retrieved
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma-data
    networks:
      - enet

  agent:
    build:
      context: .
      dockerfile: agent/.dockerfile
    depends_on:
      - chroma
      - rabbitmq
      - redis
    command: ["python", "-m", "app.main"]
    env_file:
      - .env
      - keys.env
    networks:
      - enet

  agent-cli:
    profiles: ["cli"]
    build:
      context: .
      dockerfile: agent/.dockerfile
    stdin_open: true
    tty: true
    depends_on:
      - chroma
      - redis
      - rabbitmq
    command: ["python", "-m", "app.basic_cli"]
    env_file:
      - .env
      - keys.env
    networks:
      - enet

  agent-test:
    profiles: ["test"]
    build:
      context: .
      dockerfile: agent/.dockerfile
    depends_on:
      chroma:
        condition: service_started
      redis:
        condition: service_started
      rabbitmq:
        condition: service_started
    command: ["pytest", "-v", "tests", "--tb=short", "--cache-clear"]
    env_file:
      - .env
      - keys.env
    environment:
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - REDIS_URL=redis://redis:6379/0
    networks:
      - enet

  gateway-test:
    profiles: ["test"]
    build:
      context: .
      dockerfile: gateway/.dockerfile
    depends_on:
      rabbitmq:
        condition: service_started
      redis:
        condition: service_started
      chroma:
        condition: service_started
      agent:
        condition: service_started
      metrics:
        condition: service_started
    command: ["pytest", "-v", "tests", "--tb=short", "-m", "not (integration or e2e)", "--cache-clear"]
    env_file:
      - .env
      - keys.env
    environment:
      - GATEWAY_TEST_MODE=1
      - DISABLE_QUOTA_CHECKS=1
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - REDIS_URL=redis://redis:6379/0
    networks:
      - enet

  integration-test:
    profiles: ["test"]
    build:
      context: .
      dockerfile: gateway/.dockerfile
    depends_on:
      gateway:
        condition: service_started
      rabbitmq:
        condition: service_started
      redis:
        condition: service_started
      chroma:
        condition: service_started
      agent:
        condition: service_started
    command: ["pytest", "-v", "-m", "integration or e2e", "tests/test_system_integration.py", "--tb=short", "--cache-clear"]
    env_file:
      - .env
      - keys.env
    environment:
      - GATEWAY_TEST_MODE=1
      - DISABLE_QUOTA_CHECKS=1
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - REDIS_URL=redis://redis:6379/0
    networks:
      - enet

  gateway:
    build:
      context: .
      dockerfile: gateway/.dockerfile
    ports:
      - "8080:8080"
    depends_on:
      - rabbitmq
      - redis
      - agent
    command: ["python", "-m", "app.main"]
    env_file:
      - .env
      - keys.env
    environment:
      - DISABLE_QUOTA_CHECKS=1
    networks:
      - enet

  api-cli:
    profiles: ["cli"]
    build:
      context: .
      dockerfile: apicli/.dockerfile
    stdin_open: true
    tty: true
    depends_on:
      gateway:
        condition: service_started
    command: [ "python", "-m", "app.apicli" ]
    env_file:
      - .env
      - keys.env
    environment:
      - GATEWAY_URL=http://gateway:8080
    networks:
      - enet

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: ["redis-server", "--appendonly", "yes"]
    networks:
      - enet

  metrics:
    build:
      context: .
      dockerfile: metrics/.dockerfile
    depends_on:
      - rabbitmq
    env_file:
      - .env
      - keys.env
    environment:
      - QUEUE_NAME=${AGENT_INPUT_QUEUE:-agent.mandates}
      - QUEUE_DEPTH_METRICS_INTERVAL=${QUEUE_DEPTH_METRICS_INTERVAL:-5}
    networks:
      - enet

volumes:
  redis_data:

networks:
  enet:
    driver: bridge
